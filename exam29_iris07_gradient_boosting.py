# -*- coding: utf-8 -*-
"""exam29_iris07_Gradient_Boosting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aGUNC6kHwrbUqSa7OcJJvhNsOyVYMA1J
"""



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.model_selection import *
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn import tree

plt.rcParams['figure.figsize'] = [7, 7]
sns.set(style='darkgrid')
plt.rcParams['scatter.edgecolors'] = 'black'
pd.set_option('display.max_columns', None)
pd.set_option('display.max_row', None)
pd.set_option('display.unicode.east_asian_width', True)

iris_dataset = load_iris()
iris = pd.DataFrame(iris_dataset.data,
        columns=iris_dataset.feature_names)
labels = iris_dataset.target_names
iris.info()
print(iris.head())

label = iris_dataset.target
print(label)

scaler = StandardScaler()
iris = scaler.fit_transform(iris)
Features = pd.DataFrame(iris, columns=['SL', 'SW', 'PL', 'PW'])
print(Features.shape)

X_train, X_test, Y_train, Y_test = train_test_split(
            Features, label, test_size=0.2)

n_estimators = [50, 100, 150, 200, 250, 300, 350, 400]
learning_rate = [0.1, 0.2, .3, .4, .5, .6, .7, .8, .9, 1.0]
max_depth = [2, 3, 4, 5, 6, 7, 8]
param = {'n_estimators':n_estimators, 'learning_rate':learning_rate,
         'max_depth':max_depth}
cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, 
                            random_state=868)
iris_GBC = GridSearchCV(estimator=GradientBoostingClassifier(),
            param_grid=param, scoring='accuracy',
            n_jobs=-1, cv=cv)
iris_GBC.fit(X_train, Y_train)

print(iris_GBC.best_score_)
print(iris_GBC.best_params_)
print(iris_GBC.best_estimator_)

for i in range(1, 100):
    X_train, X_test, Y_train, Y_test = train_test_split(
            Features, label, test_size=0.2, random_state=i)
    iris_GBC_best = iris_GBC.best_estimator_
    iris_GBC_best.fit(X_train, Y_train)

    train_score = iris_GBC_best.score(X_train, Y_train)
    test_score = iris_GBC_best.score(X_test, Y_test)
    if test_score >= train_score:
        print('test:{} train:{} random_state:{}'.format(
            test_score, train_score, i))

X_train, X_test, Y_train, Y_test = train_test_split(
          Features, label, test_size=0.2, random_state=42)
iris_GBC_best = iris_GBC.best_estimator_# 실행문구
iris_GBC_best.fit(X_train, Y_train)

train_score = iris_GBC_best.score(X_train, Y_train)
test_score = iris_GBC_best.score(X_test, Y_test)
if test_score >= train_score:
  print('test : {} train: {} '.format(test_score, train_score))

pd.DataFrame(confusion_matrix(Y_test, iris_GBC_best.predict(X_test)),
        columns=['P_setosa', 'P_versicolor', 'P_virginica'],
        index=['A_setosa', 'A_versicolor', 'A_virginica'])

print(classification_report(Y_test, iris_GBC_best.predict(X_test)))