# -*- coding: utf-8 -*-
"""exam19_multi_variation_predict_daily_stock_price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b9mnapw4vWC-oVMONBWu70mIRmrmVePP
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping
import pickle

raw_data = pd.read_csv('./datasets/samsung200101_220328.KS.csv')
print(raw_data.head())
raw_data.info()

raw_data['Date'] = pd.to_datetime(raw_data['Date'])
raw_data.set_index('Date', inplace= True)
print(raw_data.head())

minmaxscaler = MinMaxScaler()
scaled_data = minmaxscaler.fit_transform(raw_data)
print(scaled_data[:5])
print(scaled_data.shape)

sequence_X = []
sequence_Y = []

for i in range(len(scaled_data)-30):
  x = scaled_data[i:i+30]
  y = scaled_data[i+30][3] # 종가만 예측
  sequence_X.append(x)
  sequence_Y.append(y)

sequence_X = np.array(sequence_X)
sequence_Y = np.array(sequence_Y)
print(sequence_X[0])
print(sequence_Y[0])
print(sequence_X.shape)
print(sequence_Y.shape)

X_train, X_test, Y_train, Y_test = train_test_split(
    sequence_X, sequence_Y , test_size=0.2)
xy = X_train, X_test, Y_train, Y_test
np.save('./samsung_preprocessed_30.npy', xy)

with open('./samsung_minmaxscaler.pickle', 'wb') as f:
  pickle.dump(minmaxscaler, f)

with open('./samsung_minmaxscaler.pickle', 'rb') as f:
  minmaxscaler = pickle.load(f)

model = Sequential()
model.add(LSTM(50, input_shape=(30,6), # scaled_data.shape의 형식과 맞게
               activation = 'tanh')) #LSTM은 activation으로 tanh, tanh는 -1 ~ 1 사이의 값
model.add(Flatten())
model.add(Dense(1)) # 예측한 값을 그래도 써야 하기 때문에 마지막에는 activation을 사용하지 않는다
model.compile(loss = 'mse', optimizer='adam') # 분류가 아니므로 metrics를 안 쓴다.
model.summary()

early_stopping = EarlyStopping(monitor='val_loss', patience=30)
fit_hist= model.fit(X_train, Y_train, batch_size=128, epochs= 500, callbacks=[early_stopping], verbose=1, validation_data = (X_test, Y_test), shuffle=False)

plt.plot(fit_hist.history['loss'], label = 'loss')
plt.plot(fit_hist.history['val_loss'], label = 'val_loss')
plt.legend()
plt.show()

pred = model.predict(X_test)

plt.plot(Y_test[:30], label = 'actual')
plt.plot(pred[:30], label = 'predict')
plt.legend()
plt.show()

