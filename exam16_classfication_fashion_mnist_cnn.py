# -*- coding: utf-8 -*-
"""exam16_classfication_fashion_MNIST_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WO0NRNL3WL8Hss9S_9ENE-SEgBw3Jt_2

지금까지는 일반적인 인공신경망, Dense(조밀 신경말)<br>
앞으로 할 것은 CNN(Convolutional Neural Networks)-> 영상에 특화된 알고리즘<br>
https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten # 이미지를 28 * 28 을 한 줄((784)로 해주는 함수
from tensorflow.keras import datasets # 이미 train, test 가 나눠져 있다.
from keras.utils import np_utils

(X_train, Y_train), (X_test, Y_test) = datasets.fashion_mnist.load_data()
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

label = ['T-shirt', 'trouser', 'pullover', 'dress', 'coat',
         'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']

my_sample = np.random.randint(60000)
plt.imshow(X_train[my_sample], cmap = 'gray')
plt.show()
print(Y_train[my_sample]) # Y 값 one hot, scailing
print(X_train[my_sample]) # 이미지는 각자의 픽셀의 값을 숫자로 나타낸 것



y_train = np_utils.to_categorical(Y_train) #ont hot을 자동으로 해주는 함수, to_categorical, OneHotEncoder, get_dummies 
y_test = np_utils.to_categorical(Y_test)
print(Y_train[5000])
print(y_train[5000])

x_train = X_train / 255 # MinMaxScaler
x_test = X_test / 255
x_train = x_train.reshape(60000, 28, 28, 1)
x_test = x_test.reshape(10000, 28, 28, 1)
print(x_train.shape)
print(x_train[0])
print(x_test.shape)
print(x_test[0])
# reshape을 하지 않고 이미지 그래도 들어간다

model = Sequential()
model.add(Conv2D(32, kernel_size = (3,3), input_shape=(28, 28,1), padding = 'same', activation = 'relu')) #padding = 'same' 입력이미지와 출력 이미지의 크기가 같다 28 * 28, 32=>출력계수(필터의 개수, 다양한 필터 적용) 필터를 적용한 이미지가 32개
model.add(MaxPool2D(padding = 'same', pool_size = (2,2))) # 2 *2의 필터 안에서 가장 큰 값만 남긴다, 2칸씩 이동, 칸이 맞지 않아 부족할 경우 버린다, padding = 'same'을 넣으면 추가한다. 14 * 14
model.add(Conv2D(32, kernel_size = (3,3), padding = 'same', activation = 'relu')) #14*14, 32=>출력계수(필터의 개수, 다양한 필터 적용) 3*3의 필터 세트가 32개 존재 각각의 이미지에 세트가 만들어져 세트끼리만 적용(첫 번째 이미지 - 첫 번째 필터) 
# 그후 같은 위치의 픽셀 값을 더해서 하나의 이미지 완성, 그런 이미지가 32개 필요-> 3*3의 필터가 32개가 32개 필요
model.add(MaxPool2D(padding = 'same', pool_size = (2,2)))# 7*7
model.add(Flatten())

model.add(Dense(128, activation = 'relu'))
model.add(Dense(10, activation = 'softmax'))

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',
              metrics = ['accuracy'])
model.summary()

fit_hist = model.fit(x_train, y_train, batch_size=128, epochs = 5, validation_split = 0.2, verbose = 1)

score = model.evaluate(x_test, y_test, verbose = 0)
print('Final test set accurecy', score[1])

plt.plot(fit_hist.history['accuracy'])
plt.plot(fit_hist.history['val_accuracy'])
plt.show()

my_sample = np.random.randint(10000)
plt.imshow(X_test[my_sample], cmap = 'gray')
print(Y_test[my_sample])
print(label[Y_test[my_sample]])
pred = model.predict(x_test[my_sample].reshape(-1, 28, 28, 1))
print(pred)
print(label[np.argmax(pred)])

"""지금까지는 일반적인 인공신경망, Dense(조밀 신경말)<br>
앞으로 할 것은 CNN(Convolutional Neural Networks)-> 영상에 특화된 알고리즘

"""



"""https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"""

