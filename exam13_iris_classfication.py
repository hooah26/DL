# -*- coding: utf-8 -*-
"""exam13_iris_classfication.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IxjKCPx2tiinP4IojQ651-K9PsEvw0AD
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.optimizers import Adam

iris = load_iris() # dict 형식으로 된 자료 
print(type(iris))
print('Data :', iris.data.shape)
print('Label :', iris.target.shape)
print('feature name :', iris.feature_names)
print('target :', iris.target_names)
print('iris dataset keys\n', iris.keys())

x = iris.data
y = iris.target

# class 가 2개라고 2진 분류기가 아니다. ex) 개 or 고양이 사진 분류는 2진 분류기가 아니라 다중분류기

encoder = OneHotEncoder(sparse = False) #sparse = False 원래 값이 출력된다
y = y.reshape(-1,1) # 1개씩 묶을 수 있는대로 묶어라
encoded_y = encoder.fit_transform(y)
print(encoded_y.shape)
print(encoded_y[50:55])

X_train, X_test, Y_train, Y_test = train_test_split(
    x, encoded_y, test_size= 0.2)
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

model = Sequential()
model.add(Dense(256, input_dim=4, activation='relu'))   #feature name 4개였지 data shape도 그렇고
model.add(Dense(128, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(3, activation='softmax'))   #3개의 값을 확률값으로 바꿔줌. 즉 출력의 3가지 경우의 확률 합하면 1이됨.

opt = Adam(lr = 0.1) # learning rate를 설정해 주는 것(step 사이즈 제한) adam은 알아서 값을 잡는다, 그래도 값을 주고 싶으면 지정 가능
model.compile(opt, loss = 'categorical_crossentropy', # 다중일 때는 categorical_crossentropy
              metrics = ['accuracy'])
model.summary()

fit_hist = model.fit(X_train, Y_train, batch_size = 5,
                     epochs = 20, verbose = 1)

score = model.evaluate(X_test, Y_test, verbose = 0)
print('Final test set accuracy',score[1])

plt.plot(fit_hist.history['accuracy'])
plt.show()

my_sample = np.random.randint(30) # 0~ 29 까지 같은 확률로
sample = X_test[my_sample] #X_test에서 random 하게 하나 뽑은 것
print(sample)

sample = sample.reshape(-1, 4) # 4개의 자료를 한 번 더 묶어서 
print(sample)

pred  = model.predict(sample)
print('pred is :',pred) # 확률 값 3개를 합치면 1, ex) 0.51391697 의 확률로 중간의 것
print('actual is :', Y_test[my_sample])
print('Target :', iris.target_names[np.argmax(Y_test[my_sample])]) # argmax=> Y_test[my_sample]안의 값 중 가장 큰 값 return
print('Prediction after learning is :', iris.target_names[np.argmax(pred)]) # pred 의 가장 큰 값 return

