# -*- coding: utf-8 -*-
"""esam12_titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KTntLphcM27VyaBMe7GGFIpKMfup9jH0
"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

raw_data = sns.load_dataset('titanic')
print(raw_data)

print(raw_data.isnull().sum())

clean_data = raw_data.dropna(axis = 1, thresh = 500)
print(clean_data)

mean_age = clean_data['age'].mean()
print(mean_age)

clean_data['age'].fillna(mean_age, inplace = True)
print(clean_data.head())

clean_data.drop(['embark_town', 'alive'], axis = 1, inplace=True)

print(clean_data)

clean_data['embarked'].fillna(method = 'ffill', inplace = True)
print(clean_data.isnull().sum())

label = list(clean_data.columns)
keep = label.pop(0)
target =  clean_data[[keep]]
training_data = clean_data[label]
print(training_data.head())
print(target.head())

value_data = training_data[['age', 'fare']]
print(value_data.head())

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_data = scaler.fit_transform(value_data) # 표준화 평균 0 표준편차 1
value_data = pd.DataFrame(scaled_data, columns = value_data.columns)
print(value_data.describe())

"""
onehot_data = pd.get_dummies(training_data, columns = training_data.columns)
print(onehot_data)"""

onehot_data= pd.get_dummies(training_data, columns= training_data.columns)   #디폴트로는 int타입은 안해주니까 columns에 전체 컬럼 넣는다고 대입함.
print(onehot_data.head())

traning_data = pd.concat((onehot_data, value_data), axis = 1)
print(traning_data.info())

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(
    traning_data, target, test_size = 0.2)
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
model = Sequential()
model.add(Dense(128, input_dim = 34, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(256, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(512, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(128, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(64, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(32, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(1, activation = 'sigmoid'))
model.summary()

model.compile(loss='mse', optimizer = 'adam',
              metrics=['binary_accuracy'])
fit_hist = model.fit(
    X_train, Y_train, batch_size=50, epochs=30,
    validation_split=0.2, verbose=1
)

plt.plot(fit_hist.history['binary_accuracy'])
plt.plot(fit_hist.history['val_binary_accuracy'])

score = model.evaluate(X_test, Y_test, verbose=0)
print('loss :', score[0])
print('accuracy :', score[1])

