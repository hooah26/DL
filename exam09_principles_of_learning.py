# -*- coding: utf-8 -*-
"""exam09_principles_of_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rJO5sWEjEtbaMoIqHiuClAlkrXOatfuw
"""

import numpy as np
import matplotlib.pyplot as plt

class add_graph:
  def __init__(self):
    pass
  def forward(self, x, y):
    out = x + y
    return out
  def backward(self, dout):
    dx = 1 * dout # x +y 를 미분 =>1
    dy = 1 * dout
    return dx, dy

class mul_graph:
  def __init__(self):
    self.x = None
    self.y = None
  def forward(self, x, y):
    self.x = x # 지역변수로 남기지 않고 나중에도 x,y 를 쓰기 위래 self변수에 저장
    self.y = y
    out = x * y
    return out
  def backward(self, dout):
    dx = self.y * dout
    dy = self.x * dout
    return dx, dy

class mse_graph:
  def __init__(self):
    self.loss= None
    self.y = None  #예측값
    self.t = None     #정답
    self.x  = None #입력값
  def forward(self, y, t):
    self.t= t
    self.y= y
    self.loss = np.square(self.t - self.y).sum()/ self.t.shape[0]   #에러제곱의 평균. 개수로 나눈거니까
    return self.loss
  def backward(self, x, dout=1):   #미분할거임
    data_size= self.t.shape[0]
    dweight_mse = ((self.y - self.t)*x).sum()*2/ data_size      #mse를 가중치에 대해 미분
    dbias_mse=   (self.y - self.t).sum()*2/ data_size           #mse를 bias에 대해 미분
    return dweight_mse, dbias_mse

apple = 100
apple_num = 2
orange = 150
orange_num = 3
tax = 1.1

mul_apple_graph = mul_graph()
mul_orange_graph = mul_graph()
add_apple_orange_graph = add_graph()
mul_tax_graph = mul_graph()

apple_price = mul_apple_graph.forward(apple, apple_num)
orange_price = mul_orange_graph.forward(orange, orange_num)
all_price = add_apple_orange_graph.forward(apple_price, orange_price)
total_price = mul_tax_graph.forward(all_price, tax)
print(total_price)

dprice = 1 # 맨 끝단에 줄 미분값이 없기 때문에 1을 부여
dall_price, dtax = mul_tax_graph.backward(dprice)
dapple_price, dorange_price = add_apple_orange_graph.backward(dall_price)
dorange, dorange_num = mul_orange_graph.backward(dorange_price)
dapple, dapple_num = mul_apple_graph.backward(dapple_price)
print('dApple', dapple) # apple이 1 증가할 때 2.2 증가
print('dApple_num', dapple_num) # dapple_num 1 증가할 때 110 증가
print('dOrange', dorange)# dorange 1 증가할 때 3.3 증가
print('dOrange_num', dorange_num) # dorange_num 1 증가할 때 165 증가  => 각각의 노들을의 값이 결과값에 끼치는 영향의 크기

def celsius_to_fahrenheit(x):
  return x * 1.8 +32

data_C = np.array(range(100)) # scaling 하는 이유 미분값이 너무 클 경우 발산할 가능성이 있기에
data_F = celsius_to_fahrenheit(data_C)
scaled_data_C = data_C / 100
scaled_data_F = data_F / 100
print(scaled_data_C)
print(scaled_data_F)

weight = np.random.uniform(0, 5, 1) # 0 ~ 5 사이 값 1개
print(weight)
bias = 0

weight_graph = mul_graph() # 곱셈그래프 1개
bias_graph = add_graph() # 덧셈그래프 1개

weighted_data = weight_graph.forward(weight, scaled_data_C)  #섭씨 온도 scaled_data_C(100개)
predict_data = bias_graph.forward(weighted_data, bias)
# print(weighted_data)
print(predict_data)

dout = 1
dbias, dbiased_data = bias_graph.backward(dout)
dweight, dscaled_data_C = weight_graph.backward(dbiased_data)
print(dbias)
print(dweight)

mseGraph = mse_graph()
mse = mseGraph.forward(predict_data, scaled_data_F)
print(mse)

weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)
print(weight_mse_gradient)
print(bias_mse_gradient)
  #mse의 weight에 대한 미분값. gradient는 기울기임

learning_rate = 0.1
learning_weight = weight - learning_rate * weight_mse_gradient * np.average(dweight)
print(learning_weight)
print(weight)

learned_bias = bias - learning_rate * bias_mse_gradient * dbias
print(learned_bias)
print(bias)

weight = np.random.uniform(0, 5, 1) # 0 ~ 5 사이 값 1개
bias = 0
dout = 1
learning_rate = 0.1
error_list = []
for i in range(1000):
  #forward
  weighted_data = weight_graph.forward(weight, scaled_data_C)  
  predict_data = bias_graph.forward(weighted_data, bias)
  #backward
  dout = 1
  dbias, dbiased_data = bias_graph.backward(dout)
  dweight, dscaled_data_C = weight_graph.backward(dbiased_data)
  #mse
  mse = mseGraph.forward(predict_data, scaled_data_F)
  error_list.append(mse)
  weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)
  #learning -> wight bias 수정
  weight = weight - learning_rate * weight_mse_gradient * np.average(dweight) # 원래값 - learning_rate *평균제곱오차의 미분값 * 원래값의 미분값
  bias = bias - learning_rate * bias_mse_gradient * dbias
print(weight)
print(bias)

print(error_list[-1])

plt.plot(error_list)
plt.show()

