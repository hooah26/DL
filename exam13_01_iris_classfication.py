# -*- coding: utf-8 -*-
"""exam13_01_iris_classfication.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gnO24snMwfiFA7rlDM5Ib9y_kLa3UN0H
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
from sklearn.preprocessing import OneHotEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam

iris = load_iris()
print(type(iris))
print('Data :', iris.data.shape)
print('Label :', iris.target.shape)
print('feature name :', iris.feature_names)
print(' target name', iris.target_names)
print('iris dataset keys\n', iris.keys())

x = iris.data
y = iris.target

encoder = OneHotEncoder(sparse=False)
y = y.reshape(-1, 1)
encoded_y = encoder.fit_transform(y)
print(encoded_y.shape)
print(encoded_y[50:55])
print(y[50:55])

def build_DNN():
    model = Sequential()
    model.add(Dense(256, input_dim=4, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(512, activation='relu'))
    model.add(Dense(3, activation='softmax'))
    opt = Adam(lr=0.01)
    model.compile(opt, loss='categorical_crossentropy',
              metrics=['accuracy'])
    return model

train_scores = []
test_scores = []
for i in range(1, 10):
    X_train, X_test, Y_train, Y_test = train_test_split(
    x, encoded_y, test_size=0.2, random_state=i)
    model = build_DNN()
    fit_hist = model.fit(X_train, Y_train, batch_size=5, 
                     epochs=10, verbose=0)
    train_scores.append(fit_hist.history['accuracy'][-1])
    test_scores.append(model.evaluate(X_test, Y_test, verbose=0)[1])

print(train_scores)

print(test_scores)

X_train, X_test, Y_train, Y_test = train_test_split(
    x, encoded_y, test_size=0.2, random_state=9)
model = build_DNN()
fit_hist = model.fit(X_train, Y_train, batch_size=5, 
                    epochs=10, verbose=0)
print(fit_hist.history['accuracy'][-1])
print(model.evaluate(X_test, Y_test, verbose=0)[1])

def build_DNN_hidden_num(hidden_params):
    model = Sequential()
    model.add(Dense(hidden_params[0], input_dim=4, activation='relu'))
    model.add(Dense(hidden_params[1], activation='relu'))
    model.add(Dense(hidden_params[2], activation='relu'))
    model.add(Dense(3, activation='softmax'))
    opt = Adam(lr=0.01)
    model.compile(opt, loss='categorical_crossentropy',
              metrics=['accuracy'])
    return model

hidden_params = [[1024, 64, 32], [512, 64, 32], [64, 64, 32]]
for param in hidden_params:
    model = build_DNN_hidden_num(param)
    fit_hist = model.fit(X_train, Y_train, batch_size=5, 
                    epochs=10, verbose=0)
    print(fit_hist.history['accuracy'][-1])
    print(model.evaluate(X_test, Y_test, verbose=0)[1])

hidden_params = [[512, 256, 128], [256, 128, 64], [256, 64, 32]]
for param in hidden_params:
    model = build_DNN_hidden_num(param)
    fit_hist = model.fit(X_train, Y_train, batch_size=5, 
                    epochs=10, verbose=0)
    print(fit_hist.history['accuracy'][-1])
    print(model.evaluate(X_test, Y_test, verbose=0)[1])

hidden_params = [[1024, 64, 32], [512, 64, 32], [64, 64, 32]]
for param in hidden_params:
    model = build_DNN_hidden_num(param)
    fit_hist = model.fit(X_train, Y_train, batch_size=5, 
                    epochs=10, verbose=0)
    print(fit_hist.history['accuracy'][-1])
    print(model.evaluate(X_test, Y_test, verbose=0)[1])

models = []
for i in range(10):
    model = build_DNN_hidden_num([1024, 64, 32])
    fit_hist = model.fit(X_train, Y_train, batch_size=5, 
                    epochs=10, verbose=0)
    models.append(model)

preds = []
for model in models:
  pred = model.predict(X_test)
  preds.append(pred)

preds = np.array(preds)
print(preds.shape) #model->10개 X_test ->30개, 품종3개

preds[0].shape # 첫번째 모델의 답 30개
preds[0][0].shape # 첫번째 모델의 첫번째 답

pred_value = []
for j in range(len(X_test)):
  pred_result = []
  for i in range(10):
    pred_result.append(np.argmax(preds[i][j]))
  result = Counter(pred_result)
  print(result)
  max_value = 0
  max_key = 0
  for key in result.keys():
      if max_value < result[key]:
          max_value = result[key]
          max_key = key
  pred_value.append(max_key)
print(pred_value)

from collections import Counter
result = Counter(pred_result)
print(result)
max_value = 0
max_key = 0
for key in result.keys():
    if max_value < result[key]:
        max_value = result[key]
        max_key = key
print(max_key)

[np.argmax(x) for x in Y_test] # onehot encoding 되어 있는 Y_test를 풀어준다

accuracy_result = np.array(pred_value) ==  [np.argmax(x) for x in Y_test] # np.array를 하면 같은 자리에 있는 값끼리 연산을 한다 list 였다면 뒤에 붙을 뿐
print(accuracy_result.sum() / len(accuracy_result)) # 정답률

my_sample = np.random.randint(30)
sample = X_test[my_sample]
print(sample)
sample = sample.reshape(-1, 4)
print(sample)
preds = []
for model in models:
    preds.append(model.predict(sample))
pred_result = []
for i in range(10):
    pred_result.append(np.argmax(preds[i]))
result = Counter(pred_result)
max_value = 0
max_key = 0
for key in result.keys():
    if max_value < result[key]:
        max_value = result[key]
        max_key = key
print('pred is :', max_key)
print('actual is :', np.argmax(Y_test[my_sample]))
print('Target :', 
      iris.target_names[np.argmax(Y_test[my_sample])])
print('Prediction after learning is :', 
      iris.target_names[max_key])